#ПРОЕКТ "РЕНДЗЮ"
####Стороженко Андрей Андреевич, БПМИ152

##Постановка задач
В последнее время сфера машинного обучения развивается крайне стремительно. Создание искусственного интеллекта для различных игр давно интересует ученых в этой области. Стоит вспомнить матч DeepBlue (разработка IBM) против Гарри Каспарова в шахматы в 1996-1997, недавнее сражение Ли Седоля против AlphaGo (разработка DeepMind). Одни из популярных на сегодняшний день тем в машинном обучении &mdash; глубокое обучение и обучение с подкреплением. В данном проекте мы попытаемся изучить эти методы и применить их, написав программу, которая играет в Рендзю. За основу мы возьмем алгоритм AlphaGo. При этом готовые решения для игры в рендзю нами не рассматриваются. Для достижения поставленной цели необходимо решить следующие задачи:

1.  Изучение теории машинного обучения (neural networks, deep learning, reinforcement learning).
2.  Знакомство с правилами Рендзю.
3.  Создание модели для игры в Рендзю на примере AlphaGo.
4.  Сбор данных.
5.  Обучение алгоритма.
6.  Создание графического интерфейса программы.

##Технологические решения
Поскольку мы отталкиваемся от архитектуры AlphaGo, будем использовать следующие решения:

1.  Архитектура будет основана на сверточных сетях.
2.  В программе будет использована комбинация нескольких сетей (для оценки позиции, для предсказания хода).
3.  Для перебора вариантов игры будет использован поиск по дереву и метод Монте-Карло.
4.  Для обучения мы будем использовать партии профессиональных игроков, после чего дообучим сеть на игре с собой.

Программные решения, которые мы будем использовать:

1.  Основной язык &mdash; Python 3. Выбор обусловлен крайне удобными библиотеками для работы с данными и с линейной алгеброй, на которой построены используемые нами алгоритмы машинного обучения, стремительным развитием самого языка.
2.  Стандартные библиотеки для работы с машинным обучением в python: pandas (работа с данными), numpy, scipy (линейная алгебра, вычисления), matplotlib (построение графиков).
2.  Jupyter Notebook для оформления отчетов.
3.  Обучать нейронные сети мы будем с помощью Theano и TensorFlow (достаточно простые и эффективные решения). Для этого будем использовать библиотеку Keras.
4.  Для улучшения скорости вычислений задействуем вычисления на GPU с помощью технологии NVIDIA CUDA.
5.  При необходимости будем производить вычисления на удаленных серверах (aws, google cloud).

##План реализации
Работа будет разбита на несколько частей:

1.  Написание лабораторных работ для изучения принципов работы алгоритмов оптимизации (различные вариации алгоритмов градиентного спуска), архитектур нейросетей (полносвязные, сверточные), работе с библиотеками для обучения сетей (Theano, TensorFlow).
    * Сроки: ноябрь-декабрь 2016.
2.  Начало работы над программой. Сбор данных, начало написания архитектуры сети, реализация поиска по дереву. Для понимания теории будет производиться разбор статей на соответствующие темы. 
    * Сроки: январь 2017.
3.  Реализация архитектуры сети. Обучение различных нейросетей на основе партий профессиональных игроков.
    * Сроки: февраль-март 2017.
4.  Обучение готовой сети с помощью reinforcement learning.
    * Сроки: апрель-май 2017.