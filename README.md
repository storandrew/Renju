#ПРОЕКТ "РЕНДЗЮ"
####Стороженко Андрей Андреевич, БПМИ152

##Постановка задачи
В последнее время сфера машинного обучения развивается крайне стремительно. Создание искусственного интеллекта для различных игр давно интересует ученых в этой области. Стоит вспомнить первый матч компьютера против человека в шахматы в 1996-1997, недавнее сражение Ли Седоля против AlphaGo. DeepMind, команда разработчиков вышеупомянутых программ, не собирается останавливаться и занята разработкой алгоритма, способного играть в Starcraft (стратегия в реальном времени). Одни из популярных на сегодняшний день тем в машинном обучении &mdash; глубокое обучение и обучение с подкреплением. В данном проекте мы попытаемся изучить эти методы и применить их, написав программу, которая играет в Рендзю. За основу мы возьмем алгоритм AlphaGo. При этом готовые решения для игры в рендзю нами не рассматриваются.

##Технологические решения
Т.к. мы отталкиваемся от архитектуры AlphaGo, мы будем использовать следующие решения:

1.  Архитектура будет основана на сверточных сетях.
2.  В программе будет использована комбинация нескольких сетей (для оценки позиции, для предсказания хода).
3.  Для перебора вариантов игры будет использован поиск по дереву и метод Монте-Карло.
4.  Для обучения мы будем использовать партии профессиональных игроков, после чего дообучим сеть на игре с собой.

Программные решения, которые мы будем использовать:

1.  Основной язык &mdash; Python 3. Выбор обусловлен крайне удобными библиотеками для работы с данными и с линейной алгеброй, на которой построены используемые нами алгоритмы машинного обучения, стремительным развитием самого языка.
2.  Стандартные библиотеки для работы с машинным обучением в python: pandas (работа с данными), numpy, scipy (линейная алгебра, вычисления), matplotlib (построение графиков).
2.  Jupyter Notebook для оформления отчетов.
3.  Обучать нейронные сети мы будем с помощью Theano и TensorFlow (достаточно простые и эффективные решения). Для этого будем использовать библиотеку Keras.
4.  Для улучшения скорости вычислений задействуем вычисления на GPU с помощью технологии NVIDIA CUDA.
5.  При необходимости будем производить вычисления на удаленных серверах (aws, google cloud).

##План реализации
Работа будет разбита на несколько частей:

1.  Написание лабораторных работ для изучения принципов работы алгоритмов оптимизации (различные вариации алгоритмов градиентного спуска), архитектур нейросетей (полносвязные, сверточные), работе с библиотеками для обучения сетей (Theano, TensorFlow).
    * Сроки: ноябрь-декабрь 2016.
2.  Начало работы над программой. Сбор данных, начало написания архитектуры сети, реализация поиска по дереву. Для понимания теории будет производиться разбор статей на соответствующие темы. 
    * Сроки: январь 2017.
3.  Реализация архитектуры сети. Обучение различных нейросетей на основе партий профессиональных игроков.
    * Сроки: февраль-март 2017.
4.  Обучение готовой сети с помощью reinforcement learning.
    * Сроки: апрель-май 2017.